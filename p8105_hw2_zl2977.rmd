---
title: "p8105_hw2_zl2977"
author: "Zhourong Li zl2977"
date: "2020/9/29"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(dplyr)
```




## Problem 1

First, define a path to the dataset. 

```{r}
path_to_data = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx"
```


Read the Mr. Trashwheel dataset. 

```{r}
trashwheel_df = 
	read_xlsx(
		path = path_to_data,
		sheet = "Mr. Trash Wheel",
		range = cell_cols("A:N")) %>% 
	janitor::clean_names() %>% 
	drop_na(dumpster) %>% 
	mutate(
		sports_balls = round(sports_balls),
		sports_balls = as.integer(sports_balls) 
	)
```

Read precipitation data! For 2018 and 2017. 

```{r}
precip_2018 = 
	read_excel(
		"./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
		sheet = "2018 Precipitation",
		skip = 1
	) %>%
	janitor::clean_names() %>%
	drop_na(month) %>%
	mutate(year = 2018) %>%
	relocate(year)

precip_2017 = 
	read_excel(
		"./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
		sheet = "2017 Precipitation",
		skip = 1
	) %>% 
	janitor::clean_names() %>% 
	drop_na(month) %>%  
	mutate(year = 2017) %>% 
	relocate(year)
```

Now combine annual precipitation dataframes. In the following code chunk, I create a "helper" tibble that contains pairs of numeric and character ways of representing month, and then merge that (using month number as a key) with the precipitation dataset. This technique is one I use often when I need to recode a moderate or large number of values for a variable. 

```{r}
month_df = 
	tibble(
		month = 1:12,
		month_name = month.name
	)

precip_df = 
	bind_rows(precip_2018, precip_2017)

precip_df =
	left_join(precip_df, month_df, by = "month")


```

This dataset contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland. As trash enters the inner harbor, the trashwheel collects that trash, and stores it in a dumpster. The dataset contains information on year, month, and trash collected, include some specific kinds of trash. There are a total of `r nrow(trashwheel_df)` rows in our final dataset. Additional data sheets include month precipitation data. In this dataset:

* The median number of sports balls found in a dumpster in 2017 was `r trashwheel_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`
* The total precipitation in 2018 was `r precip_df %>% filter(year == 2018) %>% pull(total) %>% sum()` inches.

## Problem 2
```{r}
nyc_sub=
  read_csv(
    "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv"
  )


```

```{r}

nyc_sub=
  read_csv(
    "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv"
  )%>%

  # mutate(Route8=as.character(Route8))
  mutate(across(where(is.numeric)&starts_with("R"), as.character))%>%
  #change type of Route 8 to 11 from numeric type to char type since pivot_longer #function only combines same types of columns, where Route 1-7 are char types from #the beginning
  janitor::clean_names() %>%
  pivot_longer(
    route1:route11,
    names_to="route_number",
    names_prefix="route",
    values_to="route_name"
  )%>%
  relocate(route_number)%>%
  select(line,station_name,station_latitude,station_longitude,route_number,
          route_name,entry,vending,entrance_type,ada)%>%
  mutate(entry=ifelse(entry=="YES",TRUE,FALSE))


```

The dataset contains information about each entrance and exit for each subway station in NYC. The
dataset contains division, line, station name, station latitude/longitude, routes, entrance types, entry information, exit only information, vending, staffing, staff hours, ADA information, free crossover information, and other specific station and entrance location information. So far I have loaded the data, cleaned up the column names, fixed the spreading of the routes served.There are `r nrow(nyc_sub)` rows and `r ncol(nyc_sub)` in this dataset, in total there are `r nrow(nyc_sub)*ncol(nyc_sub)` data in this dataset. These data are tidy now.

```{r}
nyc_sub %>% distinct(line,station_name,.keep_all=TRUE)->distinct1
nrow(distinct1)
sum(pull(distinct1,ada) == TRUE)


```

```{r}
origin_nyc_sub=
  read_csv(
    "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv"
  )%>%
  janitor::clean_names()

origin_nyc_sub%>%filter(entry=="YES"& vending=="NO")->entrance_without_vending
total_vend_no=sum(pull(origin_nyc_sub,vending)=="NO")
proportion=nrow(entrance_without_vending)/total_vend_no
proportion
```
There are `r nrow(distinct1)` distinct stations, `r sum(pull(distinct1,ada) == TRUE)` stations are ADA compliant. The proportion of station entrances/ exits without vending alow entrance is `r proportion`
```{r}
sum(pull(distinct1,route_name) == "A")
# sum(pull(nyc_sub,route_name) == "A", na.rm = T)
# pull(nyc_sub,route_name)
# pull(distinct1,route_name)
adacomp=sum(pull(distinct1,route_name) == "A" & pull(distinct1,ada)=="TRUE")
```
There are `r sum(pull(distinct1,route_name) == "A")` distinct stations serve the A train. Of the stations that serve the A train, `r adacomp` are ADA compliant.

##Problem 3

```{r}
library(dplyr)
pols_month=
   read_csv(
      "./data/fivethirtyeight_datasets/pols-month.csv"
    ) %>%
separate(mon,c("year","month","day"))%>%
mutate(month=month.abb[pull(pols_month,month)])
```

```{r}
pols_month=
   read_csv(
      "./data/fivethirtyeight_datasets/pols-month.csv"
    )%>%
   separate(mon,c("year","month","day"))%>%
   mutate(month=as.numeric(month))%>%
   mutate(month=month.abb[month])%>%
   mutate(president=ifelse(prez_dem==1,"dem","gop"))

pols_month=subset(pols_month,select=-c(prez_gop,prez_dem))
pols_month=subset(pols_month,select=-c(day))

pols_month
str(pols_month)

```
```{r}

snp=read_csv(
      "./data/fivethirtyeight_datasets/snp.csv"
    )%>%
   separate(date,c("month","day","year"))%>%
   mutate(month=as.numeric(month))

snp=subset(snp,select=-c(day))
snp=arrange(snp,year,month)
snp=mutate(snp,month=month.abb[month])

```



```{r}
set.seed(12)
df <- data.frame(month = sample(12), x = LETTERS[1:12])

month.name
# factor(month.name[month], levels = month.name)

df %>%  mutate(month = factor(month.name[month], levels = month.name)) 

# df
```

