---
title: "p8105_hw2_zl2977"
author: "Zhourong Li zl2977"
date: "2020/9/29"
output: github_document
---

```{r setup, include=FALSE,warning=FALSE,message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(dplyr)
library(knitr)
```




## Problem 1

First, define a path to the dataset. 

```{r,warning=FALSE,message=FALSE}
path_to_data = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx"
```


Read the Mr. Trashwheel dataset. 

```{r,warning=FALSE,message=FALSE}
trashwheel_df = 
	read_xlsx(
		path = path_to_data,
		sheet = "Mr. Trash Wheel",
		range = cell_cols("A:N")) %>% 
	janitor::clean_names() %>% 
	drop_na(dumpster) %>% 
	mutate(
		sports_balls = round(sports_balls),
		sports_balls = as.integer(sports_balls) 
	)
```

Read precipitation data! For 2018 and 2017. 

```{r,warning=FALSE,message=FALSE}
precip_2018 = 
	read_excel(
		"./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
		sheet = "2018 Precipitation",
		skip = 1
	) %>%
	janitor::clean_names() %>%
	drop_na(month) %>%
	mutate(year = 2018) %>%
	relocate(year)

precip_2017 = 
	read_excel(
		"./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
		sheet = "2017 Precipitation",
		skip = 1
	) %>% 
	janitor::clean_names() %>% 
	drop_na(month) %>%  
	mutate(year = 2017) %>% 
	relocate(year)
```

Now combine annual precipitation dataframes. In the following code chunk, I create a "helper" tibble that contains pairs of numeric and character ways of representing month, and then merge that (using month number as a key) with the precipitation dataset. This technique is one I use often when I need to recode a moderate or large number of values for a variable. 

```{r,warning=FALSE,message=FALSE}
month_df = 
	tibble(
		month = 1:12,
		month_name = month.name
	)

precip_df = 
	bind_rows(precip_2018, precip_2017)

precip_df =
	left_join(precip_df, month_df, by = "month")


```

This dataset contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland. As trash enters the inner harbor, the trashwheel collects that trash, and stores it in a dumpster. The dataset contains information on year, month, and trash collected, include some specific kinds of trash. There are a total of `r nrow(trashwheel_df)` rows in our final dataset. Additional data sheets include month precipitation data. In this dataset:

* The median number of sports balls found in a dumpster in 2017 was `r trashwheel_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`
* The total precipitation in 2018 was `r precip_df %>% filter(year == 2018) %>% pull(total) %>% sum()` inches.

## Problem 2


```{r,warning=FALSE,message=FALSE}

nyc_sub=
  read_csv(
    "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv"
  )%>%

  mutate(across(where(is.numeric)&starts_with("R"), as.character))%>%
  #Route 1-7 are char types, we change type of Route 8 to 11  to char type as well since pivot_longer function only combines same types of columns
  janitor::clean_names() %>%
  pivot_longer(
    route1:route11,
    names_to="route_number",
    names_prefix="route",
    values_to="route_name"
  )%>%
  relocate(route_number)%>%
  select(line,station_name,station_latitude,station_longitude,route_number,
          route_name,entry,vending,entrance_type,ada)%>%
  mutate(entry=ifelse(entry=="YES",TRUE,FALSE))

nyc_sub_raw=
  read_csv(
    "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv"
  )

#show the first 6 lines of the nyc_sub table after tidying and reformatting
kable(head(nyc_sub,n=6))
```

The dataset contains information about each entrance and exit for each subway station in NYC. The
dataset contains division, line, station name, station latitude/longitude, routes, entrance types, entry information, exit only information, vending, staffing, staff hours, ADA information, free crossover information, and other specific station and entrance location information. So far I have loaded the data, cleaned up the column names, fixed the spreading of the routes served (reformat data so that route number and route name are distinct variables). Without cleaning and reformatting there are `r nrow(nyc_sub_raw)` rows and `r ncol(nyc_sub_raw)` columns in this dataset, in total there are `r nrow(nyc_sub_raw)*ncol(nyc_sub_raw)` data. After cleaning and reformatting there are `r nrow(nyc_sub)` rows and `r ncol(nyc_sub)` columns in this dataset, in total there are `r nrow(nyc_sub)*ncol(nyc_sub)` data. These data are tidy now.

```{r,warning=FALSE,message=FALSE}
nyc_sub %>% distinct(line,station_name,.keep_all=TRUE)->distinct1
```

```{r,warning=FALSE,message=FALSE}
origin_nyc_sub=
  read_csv(
    "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv"
  )%>%
  janitor::clean_names()

origin_nyc_sub%>%filter(entry=="YES"& vending=="NO")->entrance_without_vending
total_vend_no=sum(pull(origin_nyc_sub,vending)=="NO")
proportion=nrow(entrance_without_vending)/total_vend_no
```
There are `r nrow(distinct1)` distinct stations, `r sum(pull(distinct1,ada) == TRUE)` stations are ADA compliant. The proportion of station entrances/ exits without vending alow entrance is `r proportion`.
```{r,warning=FALSE,message=FALSE}
sum(pull(distinct1,route_name) == "A")
adacomp=sum(pull(distinct1,route_name) == "A" & pull(distinct1,ada)=="TRUE")
adacomp
```
There are `r sum(pull(distinct1,route_name) == "A")` distinct stations serve the A train. Of the stations that serve the A train, `r adacomp` are ADA compliant.

## Problem 3


```{r,warning=FALSE,message=FALSE}
pols=
   read_csv(
      "./data/fivethirtyeight_datasets/pols-month.csv"
    )%>%
   separate(mon,c("year","month","day"))%>%
   mutate(month=as.numeric(month))%>%
   mutate(month=month.abb[month])%>%
   mutate(president=ifelse(prez_dem==1,"dem","gop"))

pols=subset(pols,select=-c(prez_gop,prez_dem))
pols=subset(pols,select=-c(day))

#show the first 6 lines of the pols table
kable(head(pols,n=6))
```
```{r,warning=FALSE,message=FALSE}

snp=read_csv(
      "./data/fivethirtyeight_datasets/snp.csv"
    )%>%
   separate(date,c("month","day","year"))%>%
   mutate(month=as.numeric(month))%>%
   subset(select=-c(day))%>%
   arrange(year,month)%>%
   mutate(month=month.abb[month])%>%
   relocate(year,month) 


#show the first 6 lines of the snp table
kable(head(snp,n=6))
```



```{r,warning=FALSE,message=FALSE}
unemployment=read_csv(
      "./data/fivethirtyeight_datasets/unemployment.csv"
  )%>%
  rename(year=Year)%>%
  mutate(year=as.character(year))%>%
  pivot_longer(
    Jan:Dec,
    names_to="month",
    values_to="unemployment"
  )

#show the first 6 lines of the unemployment table
kable(head(unemployment,n=6))
```

```{r,warning=FALSE,message=FALSE}
merge1<-left_join(pols, snp)
merge_all<-left_join(merge1,unemployment)

#show the first 6 lines of the merge_all table
kable(head(merge_all,n=6))
```

The dataset "pols" contains `r colnames(pols)`, it has `r nrow(pols)` rows and `r ncol(pols)` columns, in total there are `r nrow(pols)*ncol(pols)` data in the "pols" dataset, the start year and end year of the "pols" dataset is `r range(pull(pols,year))`. The dataset "snp" contains `r colnames(snp)`, it has `r nrow(snp)` rows and `r ncol(snp)` columns, in total there are `r nrow(snp)*ncol(snp)` data in the "snp" dataset, the start year and end year of the "snp" dataset is `r range(pull(snp,year))`. The dataset "unemployment" contains `r colnames(unemployment)`, it has `r nrow(unemployment)` rows and `r ncol(unemployment)` columns, in total there are `r nrow(unemployment)*ncol(unemployment)` data in the "unemployment" dataset, the start year and end year of the "unemployment" dataset is `r range(pull(unemployment,year))`. The resulting dataset after merging these three datasets contains `r colnames(merge_all)`, it has `r nrow(merge_all)` rows and `r ncol(merge_all)` columns, in total there are `r nrow(merge_all)*ncol(merge_all)` data in the "merge_all" dataset, the start year and end year of the "merge_all" dataset is `r range(pull(merge_all,year))`. 