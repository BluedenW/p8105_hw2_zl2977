p8105\_hw2\_zl2977
================
Zhourong Li zl2977
2020/9/29

## Problem 1

First, define a path to the dataset.

``` r
path_to_data = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx"
```

Read the Mr. Trashwheel dataset.

``` r
trashwheel_df = 
    read_xlsx(
        path = path_to_data,
        sheet = "Mr. Trash Wheel",
        range = cell_cols("A:N")) %>% 
    janitor::clean_names() %>% 
    drop_na(dumpster) %>% 
    mutate(
        sports_balls = round(sports_balls),
        sports_balls = as.integer(sports_balls) 
    )
```

Read precipitation data\! For 2018 and 2017.

``` r
precip_2018 = 
    read_excel(
        "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
        sheet = "2018 Precipitation",
        skip = 1
    ) %>%
    janitor::clean_names() %>%
    drop_na(month) %>%
    mutate(year = 2018) %>%
    relocate(year)

precip_2017 = 
    read_excel(
        "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
        sheet = "2017 Precipitation",
        skip = 1
    ) %>% 
    janitor::clean_names() %>% 
    drop_na(month) %>%  
    mutate(year = 2017) %>% 
    relocate(year)
```

Now combine annual precipitation dataframes. In the following code
chunk, I create a “helper” tibble that contains pairs of numeric and
character ways of representing month, and then merge that (using month
number as a key) with the precipitation dataset. This technique is one I
use often when I need to recode a moderate or large number of values for
a variable.

``` r
month_df = 
    tibble(
        month = 1:12,
        month_name = month.name
    )

precip_df = 
    bind_rows(precip_2018, precip_2017)

precip_df =
    left_join(precip_df, month_df, by = "month")
```

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trashwheel collects that trash, and stores it in a dumpster. The dataset
contains information on year, month, and trash collected, include some
specific kinds of trash. There are a total of 344 rows in our final
dataset. Additional data sheets include month precipitation data. In
this dataset:

  - The median number of sports balls found in a dumpster in 2017 was 8
  - The total precipitation in 2018 was 70.33 inches.

## Problem 2

``` r
nyc_sub=
  read_csv(
    "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv"
  )%>%

  mutate(across(where(is.numeric)&starts_with("R"), as.character))%>%
  #Route 1-7 are char types, we change type of Route 8 to 11  to char type as well since pivot_longer function only combines same types of columns
  janitor::clean_names() %>%
  pivot_longer(
    route1:route11,
    names_to="route_number",
    names_prefix="route",
    values_to="route_name"
  )%>%
  relocate(route_number)%>%
  select(line,station_name,station_latitude,station_longitude,route_number,
          route_name,entry,vending,entrance_type,ada)%>%
  mutate(entry=ifelse(entry=="YES",TRUE,FALSE))

nyc_sub_raw=
  read_csv(
    "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv"
  )

#show the first 6 lines of the nyc_sub table after tidying and reformatting
kable(head(nyc_sub,n=6))
```

| line     | station\_name | station\_latitude | station\_longitude | route\_number | route\_name | entry | vending | entrance\_type | ada   |
| :------- | :------------ | ----------------: | -----------------: | :------------ | :---------- | :---- | :------ | :------------- | :---- |
| 4 Avenue | 25th St       |           40.6604 |         \-73.99809 | 1             | R           | TRUE  | YES     | Stair          | FALSE |
| 4 Avenue | 25th St       |           40.6604 |         \-73.99809 | 2             | NA          | TRUE  | YES     | Stair          | FALSE |
| 4 Avenue | 25th St       |           40.6604 |         \-73.99809 | 3             | NA          | TRUE  | YES     | Stair          | FALSE |
| 4 Avenue | 25th St       |           40.6604 |         \-73.99809 | 4             | NA          | TRUE  | YES     | Stair          | FALSE |
| 4 Avenue | 25th St       |           40.6604 |         \-73.99809 | 5             | NA          | TRUE  | YES     | Stair          | FALSE |
| 4 Avenue | 25th St       |           40.6604 |         \-73.99809 | 6             | NA          | TRUE  | YES     | Stair          | FALSE |

The dataset contains information about each entrance and exit for each
subway station in NYC. The dataset contains division, line, station
name, station latitude/longitude, routes, entrance types, entry
information, exit only information, vending, staffing, staff hours, ADA
information, free crossover information, and other specific station and
entrance location information. So far I have loaded the data, cleaned up
the column names, fixed the spreading of the routes served (reformat
data so that route number and route name are distinct variables).
Without cleaning and reformatting there are 1868 rows and 32 columns in
this dataset, in total there are 59776 data. After cleaning and
reformatting there are 20548 rows and 10 columns in this dataset, in
total there are 205480 data. These data are tidy now.

``` r
nyc_sub %>% distinct(line,station_name,.keep_all=TRUE)->distinct1
```

``` r
origin_nyc_sub=
  read_csv(
    "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv"
  )%>%
  janitor::clean_names()

origin_nyc_sub%>%filter(entry=="YES"& vending=="NO")->entrance_without_vending
total_vend_no=sum(pull(origin_nyc_sub,vending)=="NO")
proportion=nrow(entrance_without_vending)/total_vend_no
```

There are 465 distinct stations, 84 stations are ADA compliant. The
proportion of station entrances/ exits without vending alow entrance is
0.3770492.

``` r
sum(pull(distinct1,route_name) == "A")
```

    ## [1] 60

``` r
adacomp=sum(pull(distinct1,route_name) == "A" & pull(distinct1,ada)=="TRUE")
adacomp
```

    ## [1] 17

There are 60 distinct stations serve the A train. Of the stations that
serve the A train, 17 are ADA compliant.

## Problem 3

``` r
pols=
   read_csv(
      "./data/fivethirtyeight_datasets/pols-month.csv"
    )%>%
   separate(mon,c("year","month","day"))%>%
   mutate(month=as.numeric(month))%>%
   mutate(month=month.abb[month])%>%
   mutate(president=ifelse(prez_dem==1,"dem","gop"))

pols=subset(pols,select=-c(prez_gop,prez_dem))
pols=subset(pols,select=-c(day))

#show the first 6 lines of the pols table
kable(head(pols,n=6))
```

| year | month | gov\_gop | sen\_gop | rep\_gop | gov\_dem | sen\_dem | rep\_dem | president |
| :--- | :---- | -------: | -------: | -------: | -------: | -------: | -------: | :-------- |
| 1947 | Jan   |       23 |       51 |      253 |       23 |       45 |      198 | dem       |
| 1947 | Feb   |       23 |       51 |      253 |       23 |       45 |      198 | dem       |
| 1947 | Mar   |       23 |       51 |      253 |       23 |       45 |      198 | dem       |
| 1947 | Apr   |       23 |       51 |      253 |       23 |       45 |      198 | dem       |
| 1947 | May   |       23 |       51 |      253 |       23 |       45 |      198 | dem       |
| 1947 | Jun   |       23 |       51 |      253 |       23 |       45 |      198 | dem       |

``` r
snp=read_csv(
      "./data/fivethirtyeight_datasets/snp.csv"
    )%>%
   separate(date,c("month","day","year"))%>%
   mutate(month=as.numeric(month))%>%
   subset(select=-c(day))%>%
   arrange(year,month)%>%
   mutate(month=month.abb[month])%>%
   relocate(year,month) 


#show the first 6 lines of the snp table
kable(head(snp,n=6))
```

| year | month | close |
| :--- | :---- | ----: |
| 1950 | Jan   | 17.05 |
| 1950 | Feb   | 17.22 |
| 1950 | Mar   | 17.29 |
| 1950 | Apr   | 17.96 |
| 1950 | May   | 18.78 |
| 1950 | Jun   | 17.69 |

``` r
unemployment=read_csv(
      "./data/fivethirtyeight_datasets/unemployment.csv"
  )%>%
  rename(year=Year)%>%
  mutate(year=as.character(year))%>%
  pivot_longer(
    Jan:Dec,
    names_to="month",
    values_to="unemployment"
  )

#show the first 6 lines of the unemployment table
kable(head(unemployment,n=6))
```

| year | month | unemployment |
| :--- | :---- | -----------: |
| 1948 | Jan   |          3.4 |
| 1948 | Feb   |          3.8 |
| 1948 | Mar   |          4.0 |
| 1948 | Apr   |          3.9 |
| 1948 | May   |          3.5 |
| 1948 | Jun   |          3.6 |

``` r
merge1<-left_join(pols, snp)
merge_all<-left_join(merge1,unemployment)

#show the first 6 lines of the merge_all table
kable(head(merge_all,n=6))
```

| year | month | gov\_gop | sen\_gop | rep\_gop | gov\_dem | sen\_dem | rep\_dem | president | close | unemployment |
| :--- | :---- | -------: | -------: | -------: | -------: | -------: | -------: | :-------- | ----: | -----------: |
| 1947 | Jan   |       23 |       51 |      253 |       23 |       45 |      198 | dem       |    NA |           NA |
| 1947 | Feb   |       23 |       51 |      253 |       23 |       45 |      198 | dem       |    NA |           NA |
| 1947 | Mar   |       23 |       51 |      253 |       23 |       45 |      198 | dem       |    NA |           NA |
| 1947 | Apr   |       23 |       51 |      253 |       23 |       45 |      198 | dem       |    NA |           NA |
| 1947 | May   |       23 |       51 |      253 |       23 |       45 |      198 | dem       |    NA |           NA |
| 1947 | Jun   |       23 |       51 |      253 |       23 |       45 |      198 | dem       |    NA |           NA |

The dataset “pols” contains year, month, gov\_gop, sen\_gop, rep\_gop,
gov\_dem, sen\_dem, rep\_dem, president, it has 822 rows and 9 columns,
in total there are 7398 data in the “pols” dataset, the start year and
end year of the “pols” dataset is 1947, 2015. The dataset “snp” contains
year, month, close, it has 787 rows and 3 columns, in total there are
2361 data in the “snp” dataset, the start year and end year of the “snp”
dataset is 1950, 2015. The dataset “unemployment” contains year, month,
unemployment, it has 816 rows and 3 columns, in total there are 2448
data in the “unemployment” dataset, the start year and end year of the
“unemployment” dataset is 1948, 2015. The resulting dataset after
merging these three datasets contains year, month, gov\_gop, sen\_gop,
rep\_gop, gov\_dem, sen\_dem, rep\_dem, president, close, unemployment,
it has 822 rows and 11 columns, in total there are 9042 data in the
“merge\_all” dataset, the start year and end year of the “pols”
dataset is 1947, 2015.
