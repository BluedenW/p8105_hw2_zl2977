p8105\_hw2\_zl2977
================
Zhourong Li zl2977
2020/9/29

## Problem 1

First, define a path to the dataset.

``` r
path_to_data = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx"
```

Read the Mr. Trashwheel dataset.

``` r
trashwheel_df = 
    read_xlsx(
        path = path_to_data,
        sheet = "Mr. Trash Wheel",
        range = cell_cols("A:N")) %>% 
    janitor::clean_names() %>% 
    drop_na(dumpster) %>% 
    mutate(
        sports_balls = round(sports_balls),
        sports_balls = as.integer(sports_balls) 
    )
```

    ## Warning in FUN(X[[i]], ...): strings not representable in native encoding will
    ## be translated to UTF-8

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00C4>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00D6>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00E4>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00F6>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00DF>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00C6>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00E6>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00D8>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00F8>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00C5>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00E5>' to native encoding

Read precipitation data\! For 2018 and 2017.

``` r
precip_2018 = 
    read_excel(
        "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
        sheet = "2018 Precipitation",
        skip = 1
    ) %>%
    janitor::clean_names() %>%
    drop_na(month) %>%
    mutate(year = 2018) %>%
    relocate(year)

precip_2017 = 
    read_excel(
        "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
        sheet = "2017 Precipitation",
        skip = 1
    ) %>% 
    janitor::clean_names() %>% 
    drop_na(month) %>%  
    mutate(year = 2017) %>% 
    relocate(year)
```

Now combine annual precipitation dataframes. In the following code
chunk, I create a “helper” tibble that contains pairs of numeric and
character ways of representing month, and then merge that (using month
number as a key) with the precipitation dataset. This technique is one I
use often when I need to recode a moderate or large number of values for
a variable.

``` r
month_df = 
    tibble(
        month = 1:12,
        month_name = month.name
    )

precip_df = 
    bind_rows(precip_2018, precip_2017)

precip_df =
    left_join(precip_df, month_df, by = "month")
```

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trashwheel collects that trash, and stores it in a dumpster. The dataset
contains information on year, month, and trash collected, include some
specific kinds of trash. There are a total of 344 rows in our final
dataset. Additional data sheets include month precipitation data. In
this dataset:

  - The median number of sports balls found in a dumpster in 2017 was 8
  - The total precipitation in 2018 was 70.33 inches.

## Problem 2

``` r
nyc_sub=
  read_csv(
    "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv"
  )
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

``` r
nyc_sub=
  read_csv(
    "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv"
  )%>%

  # mutate(Route8=as.character(Route8))
  mutate(across(where(is.numeric)&starts_with("R"), as.character))%>%#change type of Route 8 to 11    from numeric type to char type since pivot_longer function only combines same types of columns, where Route 1-7 are char types from the beginning
  janitor::clean_names() %>%
  pivot_longer(
    route1:route11,
    names_to="route_number",
    names_prefix="route",
    values_to="route_name"
  )%>%
  relocate(route_number)%>%
  select(line,station_name,station_latitude,station_longitude,route_number,
          route_name,entry,vending,entrance_type,ada)%>%
  mutate(entry=ifelse(entry=="YES",TRUE,FALSE))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

The dataset contains information about each entrance and exit for each
subway station in NYC. The dataset contains division, line, station
name, station latitude/longitude, routes, entrance types, entry
information, exit only information, vending, staffing, staff hours, ADA
information, free crossover information, and other specific station and
entrance location information. So far I have loaded the data, cleaned up
the column names, fixed the spreading of the routes served.There are
20548 rows and 10 in this dataset, in total there are 205480 data in
this dataset. These data are tidy now.

``` r
nyc_sub %>% distinct(line,station_name,.keep_all=TRUE)->distinct1
nrow(distinct1)
```

    ## [1] 465

``` r
sum(pull(distinct1,ada) == TRUE)
```

    ## [1] 84

``` r
origin_nyc_sub=
  read_csv(
    "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv"
  )%>%
  janitor::clean_names()
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

``` r
origin_nyc_sub%>%filter(entry=="YES"& vending=="NO")->entrance_without_vending
total_vend_no=sum(pull(origin_nyc_sub,vending)=="NO")
proportion=nrow(entrance_without_vending)/total_vend_no
proportion
```

    ## [1] 0.3770492

There are 465 distinct stations, 84 stations are ADA compliant. The
proportion of station entrances/ exits without vending alow entrance is
0.3770492

``` r
sum(pull(distinct1,route_name) == "A")
```

    ## [1] 60

``` r
# sum(pull(nyc_sub,route_name) == "A", na.rm = T)
# pull(nyc_sub,route_name)
# pull(distinct1,route_name)
adacomp=sum(pull(distinct1,route_name) == "A" & pull(distinct1,ada)=="TRUE")
```

There are 60 distinct stations serve the A train. Of the stations that
serve the A train, 17 are ADA compliant.
